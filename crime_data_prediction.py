# -*- coding: utf-8 -*-
"""Crime_Data_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SBD4raEsL3pya36ubdWnOIdFDia46Jew
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_pacf, plot_acf
from statsmodels.tsa.arima_model import ARMA
import statsmodels.api as sm
import itertools
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
from statsmodels.tsa.statespace.sarimax import SARIMAX

data = pd.read_csv("Crime_Data.csv")
data.head()

data.info()

data.shape

data.isnull().sum()

Data_new = data.drop(['Mocodes','Weapon Used Cd', 'Weapon Desc', 'Crm Cd 1' , 'Crm Cd 2' , 'Crm Cd 3' , 'Crm Cd 4', 'Cross Street'], axis=1)

Data_new.isnull().sum()

Data_new.fillna(0)
Data_new['Premis Cd'].fillna(0, inplace = True)
Data_new['Premis Desc'].fillna('UNKNOWN', inplace = True)
Data_new['Vict Sex'].replace(to_replace=['H', '-'], value='X', inplace = True)
Data_new['Vict Sex'].fillna('X', inplace = True)
Data_new['Vict Descent'].fillna('X', inplace = True)

#time_field = 'DATE OCC' #time when the crime occurred
time_field = 'Date Rptd' #time when the crime reported

Data_new[time_field] = Data_new[time_field].apply(lambda x: x.split()[0])
Data_new['Year'] = Data_new[time_field].apply(lambda x: int(x.split('/')[-1]))
Data_new['Month'] = Data_new[time_field].apply(lambda x: int(x.split('/')[0]))
Data_new['Day'] = Data_new[time_field].apply(lambda x: int(x.split('/')[1]))
Data_new['Hour'] = Data_new['TIME OCC'].apply(lambda x: x//100)

Data_new.drop(Data_new[(Data_new['Year']==2024) & (Data_new['Month']==4)].index, inplace=True)

Data_new.tail(5) #Just want to check till when i have data

"""##Finding the top 10 Crime"""

crime_type_counts = Data_new['Crm Cd Desc'].value_counts()
top_10_crime_types = crime_type_counts.head(10)
plt.figure(figsize=(8, 8))
plt.pie(top_10_crime_types, labels=top_10_crime_types.index, autopct='%1.1f%%')
plt.title('Top 10 Crime Types Distribution')
plt.show()

crime_by_area = Data_new['AREA NAME'].value_counts()
crime_by_area = crime_by_area.sort_values(ascending=False)
top_10_areas = crime_by_area.head(10)
bottom_10_areas = crime_by_area.tail(10)
plt.figure(figsize=(12, 6))
plt.bar(top_10_areas.index, top_10_areas.values, color='blue', alpha=0.7, label='High Crime Areas')
plt.bar(bottom_10_areas.index, bottom_10_areas.values, color='lightblue', alpha=0.7, label='Low Crime Areas')
plt.xlabel('Area Name')
plt.ylabel('Number of Reported Crimes')
plt.title('Areas with High and Low Crime Rates')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.tight_layout()
plt.show()

fig = px.density_mapbox(Data_new.head(10000), lat = 'LAT', lon = 'LON', z = 'DR_NO',
                        radius = 8,
                        center = dict(lat =34.0545 , lon =   -118.3031),
                        zoom = 10,
                        mapbox_style = 'open-street-map',
                        width=1100,
                        height=800,
                        title="Heatmap of Crime Locations"
                        )

fig.show()

fig, ax = plt.subplots(figsize=(8, 6))
Data_new.groupby('Vict Sex')['Day'].count().sort_values(ascending=False).plot(kind='bar', ax=ax, color='skyblue', title='Crime Incidents by Victim Gender')
ax.set_ylabel('Number of Incidents')
ax.set_xlabel('Victim Gender')
plt.title('Number of Crime Incidents w.r.t. Victim Gender')
plt.tight_layout()
plt.show()

Data_new.groupby(['Year', 'Month'])['Day'].count().plot(kind='line', figsize=(12, 5))
plt.ylabel('Number of crime incidents')
plt.title('Los Angeles Crime Data Analysis', loc='left', fontsize=16)
plt.show()

pltdata = Data_new.groupby(['Month', 'Year'])['Day'].count().unstack()
pltdata.plot(kind='line', figsize=(12, 5), xticks=range(1, 13), title='Number of Crime Incidents over 12 Months')

"""Is there any pattern of the number of crime incidents over the hour? Yes.

The number of crime incidents is the highest at noon (the lunch time). The second peak is around the dinner time.
"""

Data_new.groupby(['Hour', 'Month'])['Day'].count().unstack().plot(kind='bar', figsize=(12, 5), stacked=True)
plt.title('Number of Crime Incidents over 24 Hours')

"""#Analysis of 'Age'
It shows the number of the top five descents over ages. There are two exceptional peaks: age 50 for White and age 35 for Unknown. (More explanations are waiting for experts who know more about crimes.)
"""

top5descents = Data_new.groupby(['Vict Descent'])['Day'].count().sort_values(ascending=False).index[:5]
data = Data_new[(Data_new['Vict Age']>0) & (Data_new['Vict Descent'].isin(top5descents))].copy()
vddict = {'B':'Black', 'H':'Hispanic/Latin/Mexican', 'O':'Other', 'W':'White', 'X':'Unknown'}
data['Vict Descent'] = data['Vict Descent'].apply(lambda x: vddict[x])

plt_data = data.groupby(['Vict Age', 'Vict Descent'])['Day'].count().unstack()
plt_data.plot(kind='line', figsize=(12, 5), xticks=range(0, 100, 5))
plt.title('Number of Crime Incidents over Victim Descent')

data = Data_new[(Data_new['Vict Age']>0)]
plt_data = data.groupby(['Vict Age', 'Vict Sex'])['Day'].count().unstack()
plt_data.plot(kind='line', figsize=(12, 5), xticks=range(0, 100, 5))
plt.title('Number of Crime Incidents over Victim Ages')

# Plotting a categorical estimate plot of Crime area by Descent
g = sns.catplot(y="AREA NAME", col="Vict Descent",
                col_order= Data_new['Vict Descent'].value_counts()[:3].index
                ,data=Data_new, kind="count",height=5, aspect=.8,
               order=Data_new['AREA NAME'].value_counts().index)

# Setting label an title for first facet
g.axes[0,0].set_xlabel('Number of Victims')
g.axes[0,0].set_title('Latinx Victims')

# Setting label an title for second facet
g.axes[0,1].set_xlabel('Number of Victims')
g.axes[0,1].set_title('White Victims')

# Setting label an title for third facet
g.axes[0,2].set_xlabel('Number of Victims')
g.axes[0,2].set_title('Black Victims')

#setting figure title for facetgrid plot
g.fig.suptitle('Los Angeles- Distribution of top 3 Victim Descents by Crime Area ', y = 1.05);

Data_new.reset_index(inplace=True)
Data_new['DATE OCC'] = pd.to_datetime(Data_new['DATE OCC'])
Data_new.set_index('DATE OCC', inplace=True)

monthly_crimes = Data_new.resample('MS').size()

# Optionally convert the Series to DataFrame
monthly_crimes_df = monthly_crimes.to_frame(name='crime_count')

# View the result
print(monthly_crimes_df.head())

plt.figure(figsize=(14, 7))
monthly_crimes_df.plot()
plt.title('Monthly Crime Trends')
plt.xlabel('Month')
plt.ylabel('Number of Crimes')
plt.show()

max_lags = min(100, len(monthly_crimes) - 1)
plot_acf(monthly_crimes_df, lags=max_lags, alpha=0.05)
plt.show()

decomposition = seasonal_decompose(np.log(monthly_crimes_df))
trend = decomposition.trend
seasonal = decomposition.seasonal
residual = decomposition.resid


plt.figure(figsize=(12,8))
plt.suptitle('Seasonal Decomposition', y = 1.05, size = 15)

plt.subplot(411)
plt.plot(np.log(monthly_crimes_df), label='Original', color='blue')
plt.legend(loc=1)

plt.subplot(412)
plt.plot(trend, label='Trend', color='green')
plt.legend(loc=1)


plt.subplot(413)
plt.plot(seasonal,label='Seasonality', color='orange')
plt.legend(loc=1)

plt.subplot(414)
plt.plot(residual, label='Residuals', color='pink')
plt.legend(loc=1)
plt.xlabel('Years', size= 12)

plt.tight_layout()

# calculating rolling mean and rolling standard deviation
roll_mean = monthly_crimes_df.rolling(window=4, center=False).mean()
roll_std = monthly_crimes_df.rolling(window=4, center=False).std()

fig = plt.figure(figsize=(13,5))
plt.plot(monthly_crimes_df, color='blue', label='Original')
# rolling mean
plt.plot(roll_mean, color='black', label='Rolling Mean')
# standard deviation
plt.plot(roll_std, color='green', label = 'Rolling Std')
plt.legend(loc='best')
plt.title('Rolling Mean & Standard Deviation')
plt.show(block=False)

Xo = monthly_crimes_df.index
yo = monthly_crimes_df['crime_count']

train_seto = monthly_crimes_df.loc['2020-01-01':'2022-07-31']
test_seto = monthly_crimes_df.loc['2022-07-01' : '2024-01-01' ]

X_traino, X_testo = train_seto.index , test_seto.index
y_traino, y_testo = train_seto['crime_count'] , test_seto['crime_count']

p = d = q = range(0, 3)

# generate all different combinations of p, q and q triplets
pdq = list(itertools.product(p, d, q))

# generate all different combinations of seasonal p, q and q triplets
pdqs = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]
# run a grid search with pdq and seasonal pdq parameters calculated above and get the best AIC value
ans = []
for comb in pdq:
    for combs in pdqs:
        try:
            mod = sm.tsa.statespace.SARIMAX(y_traino,
                                            order=comb,
                                            seasonal_order=combs,
                                            enforce_stationarity=False,
                                            enforce_invertibility=False)

            output = mod.fit()
            ans.append([comb, combs, output.aic])
        except:
            continue

model = SARIMAX(y_traino,
                order=(1, 0, 2),              # Non-seasonal order
                seasonal_order=(2, 0, 1, 12))  # Reduced seasonal differencing
fitted_model = model.fit()

print(fitted_model.summary())

# Safely attempt to plot diagnostics
if len(fitted_model.resid) > 12:  # Ensure there are more residuals than the largest seasonal effect
    fitted_model.plot_diagnostics(figsize=(15, 12))
    plt.show()
else:
    print("Not enough data points for diagnostic plots.")

# Generate forecast for the test set period
forecast_result = fitted_model.get_forecast(steps=len(y_testo))
mean_forecast = forecast_result.predicted_mean
confidence_intervals = forecast_result.conf_int()


plt.figure(figsize=(10, 5))
plt.plot(y_traino.index, y_traino, label='Historical Data')

plt.plot(y_testo.index, y_testo, color='r', label='Actual Test Data')
plt.plot(y_testo.index, mean_forecast, color='green', linestyle='dashed', label='Forecasted Values')

plt.fill_between(y_testo.index,
                 confidence_intervals.iloc[:, 0],
                 confidence_intervals.iloc[:, 1], color='pink', alpha=0.3, label='Confidence Intervals')


plt.ylim(0, 25000)
plt.title('SARIMAX Forecast with Confidence Bands')
plt.xlabel('Date')
plt.ylabel('Values')
plt.legend()
plt.show()

rmse = np.sqrt(mean_squared_error(y_testo, mean_forecast))
print("The Root Mean Squared Error of the forecasts is:", rmse)